# æ™ºèƒ½çˆ¬è™«å·¥ä½œæµç³»ç»Ÿ

åŸºäº crawl4ai å’Œ LLM çš„æ™ºèƒ½çˆ¬è™«å·¥ä½œæµç³»ç»Ÿï¼Œæ”¯æŒä»»åŠ¡ç®¡ç†ã€è°ƒåº¦ã€å¹¶å‘æ‰§è¡Œã€ç»“æœå­˜å‚¨ç­‰å®Œæ•´åŠŸèƒ½ã€‚

## ç›®å½•ç»“æ„

```
crawl4ai_data_crawl/
â”œâ”€â”€ src/                         # æºä»£ç 
â”‚   â”œâ”€â”€ smart_crawler.py         # æ™ºèƒ½çˆ¬è™«å¼•æ“ â­
â”‚   â”œâ”€â”€ crawler_workflow.py      # å·¥ä½œæµç³»ç»Ÿæ ¸å¿ƒ â­
â”‚   â”œâ”€â”€ cli.py                   # å‘½ä»¤è¡Œå·¥å…· â­
â”‚   â””â”€â”€ product_crawler.py       # äº§å“çˆ¬è™«ï¼ˆå¤‡ç”¨ï¼‰
â”‚
â”œâ”€â”€ configs/                     # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ config.py                # ç³»ç»Ÿé…ç½®ï¼ˆLLMã€çˆ¬è™«å‚æ•°ï¼‰âš™ï¸
â”‚   â”œâ”€â”€ config.example.py        # é…ç½®ç¤ºä¾‹
â”‚   â””â”€â”€ tasks_config.json        # ä»»åŠ¡é…ç½®ç¤ºä¾‹
â”‚
â”œâ”€â”€ templates/                   # æ•°æ®æå–æ¨¡æ¿ ğŸ“‹
â”‚   â””â”€â”€ template_*.json
â”‚
â”œâ”€â”€ docs/                        # æ–‡æ¡£ ğŸ“š
â”‚   â”œâ”€â”€ QUICKSTART.md            # å¿«é€Ÿå¼€å§‹
â”‚   â”œâ”€â”€ ARCHITECTURE.md          # ç³»ç»Ÿæ¶æ„
â”‚   â””â”€â”€ DIRECTORY.md             # ç›®å½•ç»“æ„è¯´æ˜
â”‚
â”œâ”€â”€ data/                        # æ•°æ®å­˜å‚¨ ğŸ’¾
â”‚   â””â”€â”€ tasks.json               # ä»»åŠ¡é˜Ÿåˆ—ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â”‚
â”œâ”€â”€ output/                      # çˆ¬å–ç»“æœ ğŸ“Š
â”‚   â””â”€â”€ products_*.json
â”‚
â”œâ”€â”€ logs/                        # æ—¥å¿—æ–‡ä»¶ ğŸ“
â”‚
â”œâ”€â”€ run.py                       # ä¸»å…¥å£ ğŸš€
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

è¯¦ç»†è¯´æ˜è§ [docs/DIRECTORY.md](docs/DIRECTORY.md)

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### 2. é…ç½® API Key
ç¼–è¾‘ `configs/config.py`ï¼Œè®¾ç½®ä½ çš„ LLM API Key:
```python
LLM_CONFIG = {
    "deepseek": {
        "provider": "deepseek/deepseek-chat",
        "api_token": "your-api-key-here",  # ä¿®æ”¹è¿™é‡Œ
        ...
    }
}
```

### 3. è¿è¡Œçˆ¬è™«

#### æ–¹å¼1: äº¤äº’å¼å‘½ä»¤è¡Œï¼ˆæ¨èï¼‰
```bash
python run.py
```

è¿›å…¥äº¤äº’ç•Œé¢åï¼š
```
crawler> load configs/tasks_config.json   # åŠ è½½ä»»åŠ¡
crawler> list                             # æŸ¥çœ‹ä»»åŠ¡åˆ—è¡¨
crawler> run                              # æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
crawler> show task_001                    # æŸ¥çœ‹ä»»åŠ¡è¯¦æƒ…
crawler> exit                             # é€€å‡º
```

#### æ–¹å¼2: ç›´æ¥å‘½ä»¤
```bash
# åŠ è½½å¹¶æ‰§è¡Œä»»åŠ¡
python run.py load configs/tasks_config.json
python run.py run

# æŸ¥çœ‹ä»»åŠ¡åˆ—è¡¨
python run.py list
```

#### æ–¹å¼3: ç¼–ç¨‹æ–¹å¼
```python
import asyncio
from src.crawler_workflow import CrawlerWorkflow

async def main():
    workflow = CrawlerWorkflow()

    # åˆ›å»ºä»»åŠ¡
    workflow.create_task_from_config(
        task_id="my_task",
        name="æˆ‘çš„çˆ¬å–ä»»åŠ¡",
        start_url="https://example.com",
        template_path="templates/my_template.json",
        enable_recursive=True,
        max_depth=2
    )

    # æ‰§è¡Œ
    await workflow.run_pending_tasks()
    workflow.print_summary()

asyncio.run(main())
```

## æ ¸å¿ƒåŠŸèƒ½

âœ… **æ™ºèƒ½çˆ¬å–**
- å•é¡µçˆ¬å–
- é€’å½’çˆ¬å–ï¼ˆè‡ªåŠ¨å‘ç°å­é¡µé¢ï¼‰
- LLM é©±åŠ¨çš„æ•°æ®æå–
- åŸºäºæ¨¡æ¿çš„ç»“æ„åŒ–è¾“å‡º

âœ… **ä»»åŠ¡ç®¡ç†**
- åˆ›å»ºã€åˆ é™¤ã€æŸ¥è¯¢ä»»åŠ¡
- æŒä¹…åŒ–å­˜å‚¨
- çŠ¶æ€è¿½è¸ª

âœ… **å·¥ä½œæµè°ƒåº¦**
- ä¸²è¡Œ/å¹¶å‘æ‰§è¡Œ
- ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†
- ç»“æœè‡ªåŠ¨ä¿å­˜

âœ… **æ˜“ç”¨æ€§**
- äº¤äº’å¼ CLI
- æ‰¹é‡ä»»åŠ¡é…ç½®
- é…ç½®æ–‡ä»¶ç®¡ç†

## ä½¿ç”¨ç¤ºä¾‹

### åˆ›å»ºæ¨¡æ¿
åˆ›å»º `templates/my_template.json`:
```json
{
  "äº§å“åç§°": "äº§å“çš„å®Œæ•´åç§°",
  "ä»·æ ¼": "äº§å“ä»·æ ¼ï¼ŒåŒ…å«è´§å¸å•ä½",
  "æè¿°": "äº§å“æè¿°æˆ–ç®€ä»‹"
}
```

### åˆ›å»ºä»»åŠ¡é…ç½®
åˆ›å»º `configs/my_tasks.json`:
```json
{
  "tasks": [
    {
      "task_id": "task_001",
      "name": "çˆ¬å–äº§å“ä¿¡æ¯",
      "start_url": "https://example.com",
      "template_path": "templates/my_template.json",
      "config": {
        "enable_recursive": true,
        "max_depth": 2,
        "max_pages": 10
      }
    }
  ]
}
```

### æ‰§è¡Œçˆ¬å–
```bash
python run.py
crawler> load configs/my_tasks.json
crawler> run
crawler> list
```

### æŸ¥çœ‹ç»“æœ
ç»“æœä¿å­˜åœ¨ `output/products_*.json`:
```json
{
  "template": { ... },
  "crawl_info": {
    "pages_visited": 7,
    "products_found": 2,
    "crawled_at": "2025-11-21T14:25:26"
  },
  "products": [
    {
      "äº§å“åç§°": "å®é™…æå–çš„åç§°",
      "ä»·æ ¼": "å®é™…æå–çš„ä»·æ ¼",
      "_source_url": "https://example.com/page",
      "_crawled_at": "2025-11-21T14:25:26"
    }
  ]
}
```

## CLI å‘½ä»¤

```
add <task_id> <name> <url> [template]  - æ·»åŠ ä»»åŠ¡
load <config.json>                     - ä»æ–‡ä»¶åŠ è½½ä»»åŠ¡
list                                   - åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡
show <task_id>                         - æ˜¾ç¤ºä»»åŠ¡è¯¦æƒ…
run [task_id]                          - æ‰§è¡Œä»»åŠ¡ï¼ˆä¸æŒ‡å®šåˆ™æ‰§è¡Œæ‰€æœ‰ï¼‰
delete <task_id>                       - åˆ é™¤ä»»åŠ¡
clear                                  - æ¸…ç©ºæ‰€æœ‰ä»»åŠ¡
help                                   - æ˜¾ç¤ºå¸®åŠ©
exit                                   - é€€å‡º
```

## é…ç½®è¯´æ˜

### LLM é…ç½® (`configs/config.py`)
```python
LLM_CONFIG = {
    "deepseek": {
        "provider": "deepseek/deepseek-chat",
        "api_token": "your-api-key",
        "base_url": "https://api.deepseek.com"
    }
}
```

### çˆ¬è™«é…ç½® (`configs/config.py`)
```python
CRAWLER_CONFIG = {
    "max_depth": 2,              # æœ€å¤§é€’å½’æ·±åº¦
    "max_pages": 20,             # æœ€å¤§çˆ¬å–é¡µé¢æ•°
    "output_dir": "output",      # è¾“å‡ºç›®å½•
    "enable_recursive": True,    # å¯ç”¨é€’å½’çˆ¬å–
    "template_path": "templates/template_deepseek_pricing.json",
    "start_url": "https://example.com"
}
```

## æ–‡æ¡£

- **å¿«é€Ÿå¼€å§‹**: `docs/QUICKSTART.md`
- **ç³»ç»Ÿæ¶æ„**: `docs/ARCHITECTURE.md`

## æ‰©å±•æ–¹å‘

- å®šæ—¶è°ƒåº¦ï¼ˆAPSchedulerï¼‰
- Web APIï¼ˆFastAPIï¼‰
- æ•°æ®åº“å­˜å‚¨ï¼ˆSQLite/PostgreSQLï¼‰
- ç›‘æ§å‘Šè­¦
- åˆ†å¸ƒå¼æ‰§è¡Œï¼ˆCeleryï¼‰

## License

MIT
